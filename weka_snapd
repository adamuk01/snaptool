#!/usr/bin/env python3

# Weka Snapshot Management Daemon
# Vince Fleming
# vince@weka.io
#
VERSION="0.1.0"

# system imports
import logging
import logging.handlers
from logging import debug, info, warning, error, critical
import argparse
import os
import sys
import time
import traceback
from multiprocessing import Process
import threading
import json
import yaml
import datetime
from urllib3 import add_stderr_logger
import queue

from wekacluster import WekaCluster
import signals
from snapshots import SnapSchedule, MonthlySchedule, WeeklySchedule, DailySchedule, HourlySchedule
from upload import UploadSnapshot, replay_upload_intent_log

def snapd_call_api(cluster, method, parms):
    stopit = False
    num_errors = 0
    while not stopit:
        # api only fails under extreme circumstances
        try:
            api_return = cluster.call_api(method=method,parms=parms)
            stopit = True
        #except APIException as exc:
        except Exception as exc:
            num_errors += 1
            logger.error(f"Error {exc} while executing API method {method}; attemping to re-establish communications (retry {num_errors})")
            if num_errors > 10: # give up
                raise
            time.sleep(5)               # give the cluster some time to resolve it's issues
            cluster.refresh_config()    # will try to re-establish communications
    return api_return

if __name__ == '__main__':
    # handle signals (ie: ^C and such)
    signals.signal_handling()

    parser = argparse.ArgumentParser(description="Weka Snapshot Management Daemon")
    parser.add_argument("-c", "--configfile", dest='configfile', default="./weka_snapd.yml", help="override ./weka_snapd.yml as config file")
    parser.add_argument("-p", "--port", dest='port', default="13999", help="TCP port number to listen on")
    parser.add_argument( 'clusterspec', default="localhost", help="Cluster specification.  <host>,<host>,...:authfile" )
    parser.add_argument("-v", "--verbosity", action="count", default=0, help="increase output verbosity")
    parser.add_argument("--version", dest="version", default=False, action="store_true", help="Display version number")
    args = parser.parse_args()

    if args.version:
        print( f"{sys.argv[0]} version {VERSION}" )
        sys.exit( 0 )

    if args.verbosity == 0:
        loglevel = logging.ERROR
    elif args.verbosity == 1:
        loglevel = logging.WARNING
    elif args.verbosity == 2:
        loglevel = logging.INFO
    elif args.verbosity > 2:
        loglevel = logging.DEBUG

    # set the root logger
    logger = logging.getLogger()
    FORMAT = "%(process)s:%(filename)s:%(lineno)s:%(funcName)s():%(levelname)s:%(message)s"
    logger.setLevel(loglevel)

    # create handler to log to syslog
    syslog_handler = logging.handlers.SysLogHandler(address="/dev/log")
    syslog_handler.setFormatter(logging.Formatter(FORMAT))

    # create handler to log to stderr
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(logging.Formatter(FORMAT))
    #console_handler.setLevel(loglevel)

    # add handlers to root logger
    logger.addHandler(syslog_handler)
    logger.addHandler(console_handler)

    # configure logging in signals module
    #sublog = logging.getLogger( "signals" )
    #sublog.setLevel(loglevel)

    # configure logging in wekacluster module
    sublog = logging.getLogger( "wekacluster" )
    sublog.setLevel(logging.INFO)

    # configure logging in wekaapi module
    sublog = logging.getLogger( "wekaapi" )
    sublog.setLevel(logging.ERROR)

    # configure logging in sthreads module
    sublog = logging.getLogger( "sthreads" )
    sublog.setLevel(logging.ERROR)

    # configure logging in circular module
    logging.getLogger("circular").setLevel(logging.ERROR)

    # configure logging in snapshots module
    logging.getLogger("snapshots").setLevel(logging.INFO)

    # configure logging in upload module
    logging.getLogger("upload").setLevel(logging.INFO)

    # configure logging in connectionpool module
    #logging.getLogger("connectionpool").setLevel(logging.ERROR)
    #logging.getLogger("retry").setLevel(logging.ERROR)
    # urllib3 logging
    add_stderr_logger(level=logging.ERROR)


    with open(args.configfile, 'r') as f:
        try:
            config = yaml.load(stream=f, Loader=yaml.FullLoader)
        except AttributeError:
            config = yaml.load(stream=f)

    #logger.debug(f"{json.dumps(config)}")

    #
    # Sanity-check configuration?
    #


    # create Cluster object so we can use the Weka API
    clusterspeclist = args.clusterspec.split(":")
    if len(clusterspeclist) > 1:
        cluster_auth = clusterspeclist[1]
    else:
        cluster_auth = None

    cluster_obj = WekaCluster(clusterspeclist[0], cluster_auth)

    logging.info(f"{sys.argv[0]} starting")

    # configure snap schedules
    schedules = {}
    monthly = MonthlySchedule()
    weekly = WeeklySchedule()
    daily = DailySchedule()
    hourly = HourlySchedule()
    schedules["default"] = SnapSchedule("default", monthly, weekly, daily, hourly) # defalt schedule, always there

    # custom schedules
    config_schedules = config["schedules"]
    for schedname, sched in config_schedules.items():
        #logger.debug(f"schedname={schedname}, sched={sched}")
        monthly = MonthlySchedule(date=sched['monthly']['date'], time=sched['monthly']['time'], 
                retain=sched['monthly']['retain'], upload=sched['monthly']['upload'])
        weekly = WeeklySchedule(weekday=sched['weekly']['weekday'], time=sched['weekly']['time'], 
                retain=sched['weekly']['retain'], upload=sched['weekly']['upload'])
        daily = DailySchedule(time=sched['daily']['time'], start_day=sched['daily']['start_day'], 
                stop_day=sched['daily']['stop_day'], retain=sched['daily']['retain'], upload=sched['daily']['upload'])
        hourly = HourlySchedule(start_day=sched['hourly']['start_day'], stop_day=sched['hourly']['stop_day'], 
                start_time=sched['hourly']['start_time'], stop_time=sched['hourly']['stop_time'], retain=sched['hourly']['retain'], upload=sched['hourly']['upload'])
        schedules[schedname] = SnapSchedule(schedname, monthly, weekly, daily, hourly)

    # let's get to work!

    filesystems = config["filesystems"]

    logger.warning("Replaying intent log")
    replay_upload_intent_log(cluster_obj)


    while True:

        now = datetime.datetime.now()
        logger.debug(f"current time is {now}")
        #now = datetime.datetime(2020,12,31,23,59,45) # for testing

        have_slept = False

        # get the next snap time for each of the filesystems so we can sort for earliest
        next_foreach = {}
        for fsname, filesystem in filesystems.items():
            schedname = filesystem["schedule"]
            schedule = schedules[schedname]
            next_snap = schedule.next_snap(now) # get the next snapshot object
            next_snap_time = next_snap.next_snaptime(now)   # time of next snapshot

            if next_snap_time not in next_foreach:
                next_foreach[next_snap_time] = {}
            next_foreach[next_snap_time][fsname] = next_snap    # build a dict so we can sort by snaptime; each "time" is a list of fs's

        logger.debug(f"next_foreach[next_snap_time] = {next_foreach[next_snap_time]}, next snap_time = {next_snap_time}")
        logger.debug(f"next_foreach= {next_foreach}")
        next_snaptime = min(next_foreach)       # get the earliest snaptime
        #logger.debug(f"Next snapshot due to be taken at = {next_snaptime}")

        # we should now sleep until next_snaptime; it's the next time we need to take a snap...
        time_to_snap = next_snaptime - now      # time_to_snap will be a datetime.timedelta object
        #time_to_snap -= datetime.timedelta(seconds=10)     # come in 10s early?
        sleep_time = time_to_snap.total_seconds()
        logger.info(f"Next snapshot due to be taken at = {next_snaptime}; now = {now} sleeping {sleep_time}s ({time_to_snap} h:m:s.us)")
        time.sleep(sleep_time)


        # Create Snaps
        for fsname, next_snap in next_foreach[next_snaptime].items():   # current list of snaps that need to be taken
            next_snapname = next_snap.name + "." + next_snap.next_snaptime(now).strftime("%Y-%m-%d_%H%M")
            logger.debug(f"Next snapname is {next_snapname}")

            # create a snap
            logger.debug(f"snap {next_snapname} to be created on fs {fsname}")
            try:
                created_snap = cluster_obj.call_api(method="snapshot_create",parms={
                    "file_system":fsname,
                    "name":next_snapname,
                    "access_point":next_snapname,
                    "is_writable":False})
                logger.info(f"snap {next_snapname} has been created on fs {fsname}")
                # needs error-checking
            except Exception as exc:
                logger.error(f"error creating snapshot {next_snapname} on filesystem {fsname}: {exc}")

            # upload it?
            if next_snap.upload:
                # if upload is True, queue it for uploading
                UploadSnapshot(cluster_obj, fsname, next_snapname)

        # - vince - indents matter here.  Look at this again.
        # should we loop through the list again after creating all snaps, or delete as we go?

        # Delete old snaps - start with getting a list of snaps
        try:
            snapshots = snapd_call_api(cluster_obj, method="snapshots_list",parms={})
        except Exception as exc:
            logger.error(f"Error collecting snapshot list: {exc}")
            sys.exit(1)

        logger.debug("checking if old snaps need to be removed")
        sorted_snaps = {}
        for snapshot in snapshots:
            fsname = snapshot["filesystem"]
            snapname = snapshot["name"]
            # make sure it's one of ours, not one made by the customer
            snap_list = snapname.split('.')
            logger.debug(f"looking at snap {fsname}/{snapname}")
            if len(snap_list) != 2:     #first hint - schedule.time is the format; must be 2 here 
                continue
            if snap_list[0] not in ["monthly","weekly","daily","hourly"]:    # ours start with the schedule name
                continue

            # got one of ours, record it
            if fsname not in sorted_snaps:
                sorted_snaps[fsname] = []
            logger.debug("old snap {snapname} recorded")
            sorted_snaps[fsname].append(snapname)

        # delete any old snaps
        for fsname, next_snap in next_foreach[next_snaptime].items():   # current list of snaps that have been taken
            # make a list of this schedule's snaps...
            snap_list = []
            if fsname in sorted_snaps:
                logger.debug(f"fs {fsname} should keep {next_snap.retain} {next_snap.name} snaps, and currently has {len(sorted_snaps[fsname])} of them")
                fs_snaps = sorted_snaps[fsname]
                for snapname in fs_snaps:
                    temp_list = snapname.split('.')
                    # make sure it's one of ours
                    if len(temp_list) != 2 and temp_list[0] not in ["monthly","weekly","daily","hourly"]:    # ours start with the schedule name
                        # continue here?  don't think so
                        continue
                    # if the correct schedule (ie: monthly, weekly, etc), keep it
                    if temp_list[0] == next_snap.name:
                        snap_list.append(snapname)

                    delete_list = sorted(snap_list)[next_snap.retain:]
                    logger.debug(f"delete_list = {delete_list}")
                    for snap in delete_list:
                        logger.info(f"snap {fsname}/{snap} being deleted")
                        try:
                            deleted_snap = cluster_obj.call_api(method="snapshot_delete",parms={"file_system":fsname,"name":snap})
                            logger.info(f"snap {fsname}/{snap} sucessfully deleted")
                        except Exception as exc:
                            logger.error(f"error deleting snapshot {snap} from filesystem {fsname}: {exc}")
                    



"""

            if fsname in sorted_snaps and len(sorted_snaps[fsname]) > next_snap.retain:
                # need to delete at least 1 snap - oldest first
                logger.debug(f"cleaning up old snaps")
                count = 0
                for snap in sorted(sorted_snaps[fsname]):   # sorted so oldest come up first
                    logger.debug(f"looking at snap {fsname}/{snap}")
                    count += 1
                    if count > next_snap.retain:
                        logger.info(f"snap {fsname}/{snap} being deleted")
                        try:
                            deleted_snap = cluster_obj.call_api(method="snapshot_delete",parms={"file_system":fsname,"name":snap})
                        except Exception as exc:
                            logger.error(f"error deleting snapshot {snap} from filesystem {fsname}: {exc}")


        # old code

        for fsname, filesystem in filesystems.items():
            schedname = filesystem["schedule"]
            schedule = schedules[schedname]
            next_snap = schedule.next_snap(now)

            logger.debug(f"next snap for {fsname} will be a {schedule.name} at: {next_snap}")

            time_to_snap = next_snap.next_snaptime(now) - now

            # is there a snap to be done now?
            if time_to_snap < datetime.timedelta(minutes=1):
                if not have_slept:
                    logger.debug(f"less than 1 min to go to snapshot time! Sleeping until time to snap")
                    sleep_time = time_to_snap.total_seconds()
                    if sleep_time < 0:
                        logger.error(f"negative sleep time {sleep_time}. now={now}, next_snap={next_snap}")
                    time.sleep(sleep_time)
                have_slept = True

                # process snapshots
                next_snapname = next_snap.name + "." + next_snap.next_snaptime(now).strftime("%Y-%m-%d_%H%M")
                logger.debug(f"Next snapname is {next_snapname}")

                if next_snap.retain > 0:    # number of snaps to keep >0

                    # create a snap
                    logger.debug(f"snap {next_snapname} to be created on fs {fsname}")
                    try:
                        created_snap = cluster_obj.call_api(method="snapshot_create",parms={
                            "file_system":fsname,
                            "name":next_snapname,
                            "access_point":next_snapname,
                            "is_writable":False})
                        logger.info(f"snap {next_snapname} has been created on fs {fsname}")
                        # needs error-checking
                    except Exception as exc:
                        logger.error(f"error creating snapshot {next_snapname} on filesystem {fsname}: {exc}")

                    # upload it?
                    if next_snap.upload:
                        # if upload is True, queue it for uploading
                        UploadSnapshot(cluster_obj, fsname, next_snapname)

                    # delete old snaps
                    if fsname in sorted_snaps:
                        logger.debug(f"fs {fsname} should keep {next_snap.retain} {next_snap.name} snaps, and currently has {len(sorted_snaps[fsname])} of them")
                    if fsname in sorted_snaps and len(sorted_snaps[fsname]) > next_snap.retain:
                        # need to delete at least 1 snap - oldest first
                        logger.debug(f"cleaning up old snaps")
                        count = 0
                        for snap in sorted(sorted_snaps[fsname]):   # sorted so oldest come up first
                            logger.debug(f"looking at snap {fsname}/{snap}")
                            count += 1
                            if count > next_snap.retain:
                                logger.info(f"snap {fsname}/{snap} being deleted")
                                try:
                                    deleted_snap = cluster_obj.call_api(method="snapshot_delete",parms={"file_system":fsname,"name":snap})
                                except Exception as exc:
                                    logger.error(f"error deleting snapshot {snap} from filesystem {fsname}: {exc}")


        logger.debug(f"Nothing to do; sleeping 1 min")
        time.sleep(60)
"""
